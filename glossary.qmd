# Glossary

### SHARE glossary

**Deck**: A marketing term used to refer to a slideshow presentation of some kind (i.e. a PowerPoint or Keynote)

**SIP**: *Social Intelligence Practice*- the team at Microsoft we most closely work with on projects. They sit within Microsoft's market research organisation and partner with many wider teams across Microsoft

**QBR**: *Quarterly Business Review*- a quarterly meeting where goals, outcomes, and development are reviewed. You will see this term used both for our own company QBRs, but also QBRs for clients too.

### Data Science glossary

**Embedding**: Numerical representations of real-world objects (in the form of a vector of real numbers)

**Embedding Model**: A model that can perform embedding by encapsulating information into dense representations in a multi-dimensional space

**F1 Score**: The harmonic mean of precision and recall (enables us to integrate precision and recall into a single metric)

$$
F1 \space Score = 2 \times \dfrac{Precision \times Recall}{Precision + Recall}
$$

**Precision**: The proportion of positive identifications that were actually correct. Precision focuses on the correctness of positive predictions

$$
Precision = \dfrac{TP}{(TP + FP) }
$$

**Recall**: The proportion of actual positives that were identified correctly. Recall focuses on capturing all relevant instances

$$
Recall = \dfrac{TP}{(TP + FN) }
$$

**Sentence Embedding**: A numerical representation of a sentence

**Token**: The 'building blocks' of text that are readable by a model. Depending on the specific model, a token may be a single word, a character, phrases, or parts of words. 

**Tokenization**: The act of separating a piece of text into smaller units known as tokens. 

**Word Embedding**: A numerical representation of a single word
